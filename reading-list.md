---
title: Reading List
layout: page
permalink: /reading-list/
---

<img class="card-img-top" src="/assets/img/library.jpg">

# hiddenlayers.tech reading list
<br>

## Perception

[SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers](https://arxiv.org/abs/2105.15203) (Xie, Enze, et al., 2021)

[Panoptic SegFormer: Delving Deeper into Panoptic Segmentation with
Transformers](https://arxiv.org/abs/2109.03814) (Li et al., 2022)
- Not actually a Segformer because it uses a CNN backbone.
    - Would be interesting to adapt to hierarchical transformer encoder instead.

[Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth](https://arxiv.org/abs/2201.07436) (Kim et al., 2022)
- Deformable attention inspired by deformable convolution.

[Deformable DETR: Deformable Transformers for End-to-End Object Detection](https://arxiv.org/abs/2010.04159)

[Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction
without Convolutions](https://arxiv.org/abs/2102.12122)
- Explores non-CNN backbone, all transformer-based encoder for dense prediction.
- Introduce Spatial-Resolution Attention (SRA), the efficient self-attention used in Segformer.

[Panoptic Segmentation](https://arxiv.org/abs/1801.00868) (Kirillov et al., 2019)

<br>

## Prediction, Planning, Control

[DiffStack: A Differentiable and Modular Control Stack for Autonomous Vehicles](https://arxiv.org/abs/2212.06437) (Karkus et al., 2023)

[Trajectron++: Dynamically-Feasible Trajectory Forecasting With Heterogeneous Data](https://arxiv.org/abs/2001.03093) (Salzmann et al., 2020)