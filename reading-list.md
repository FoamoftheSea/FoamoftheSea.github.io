---
title: Reading List
layout: page
permalink: /reading-list/
---

<img class="card-img-top" src="/assets/img/library.jpg">

# hiddenlayers.tech reading list
<br>

## Perception

[SegFormer: Simple and Efficient Design for Semantic Segmentation with Transformers](https://arxiv.org/abs/2105.15203) (Xie, Enze, et al., 2021)

[Panoptic SegFormer: Delving Deeper into Panoptic Segmentation with
Transformers](https://arxiv.org/abs/2109.03814) (Li et al., 2022)

[Global-Local Path Networks for Monocular Depth Estimation with Vertical CutDepth](https://arxiv.org/abs/2201.07436) (Kim et al., 2022)

[Deformable DETR: Deformable Transformers for End-to-End Object Detection](https://arxiv.org/abs/2010.04159)

[Pyramid Vision Transformer: A Versatile Backbone for Dense Prediction
without Convolutions](https://arxiv.org/abs/2102.12122)
- Introduces Spatial-Resolution Attention (SRA), the efficient self-attention used in Segformer.

[Panoptic Segmentation](https://arxiv.org/abs/1801.00868) (Kirillov et al., 2019)

[How Much Position Information Do Convolutional Neural Networks Encode?](https://arxiv.org/abs/2001.08248) (Islam et al., 2020)
- Shows that CNNs actually do encode positional information that seems to be provided by zero padding.

<br>

## Prediction, Planning, Control

[DiffStack: A Differentiable and Modular Control Stack for Autonomous Vehicles](https://arxiv.org/abs/2212.06437) (Karkus et al., 2023)

[Trajectron++: Dynamically-Feasible Trajectory Forecasting With Heterogeneous Data](https://arxiv.org/abs/2001.03093) (Salzmann et al., 2020)